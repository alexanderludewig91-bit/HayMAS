# ğŸ” Deep Research Tool-Landschaft

Eine umfassende Ãœbersicht Ã¼ber Recherche-Tools fÃ¼r KI-Agenten, basierend auf Best Practices aus professionellen Research-Tools.

---

## Ãœbersicht: Tool-Kategorien

| Tier | Kategorie | Beispiele |
|------|-----------|-----------|
| 1 | Basis-Suche | Tavily, SerpAPI, Brave |
| 2 | News & AktualitÃ¤t | Google News, NewsAPI, GDELT |
| 3 | Wissenschaft | Semantic Scholar, arXiv, PubMed |
| 4 | Unternehmen | OpenCorporates, North Data, Crunchbase |
| 5 | Patente & IP | Espacenet, DPMA, USPTO |
| 6 | Verwaltung & Recht | TED, EUR-Lex, Gesetze-im-Internet |
| 7 | Statistik & Open Data | Destatis, Eurostat, World Bank |
| 8 | Social Media & Trends | Reddit, Hacker News, Google Trends |
| 9 | Spezial-Datenbanken | Wikipedia, Wikidata, Wolfram Alpha |

---

## Tier 1: Basis-Suche

Allgemeine Websuche - der Fallback fÃ¼r alles.

| Tool | Beschreibung | API | Kosten | QualitÃ¤t |
|------|--------------|-----|--------|----------|
| **Tavily** | FÃ¼r LLMs optimierte Suche, gute Snippets | âœ… | ~$5/1000 | â­â­â­â­ |
| **SerpAPI** | Google-Ergebnisse exakt wie Browser | âœ… | ~$50/5000 | â­â­â­â­â­ |
| **Brave Search** | Datenschutz-fokussiert, eigener Index | âœ… | Free Tier | â­â­â­â­ |
| **Bing Search** | Microsoft, gut fÃ¼r allgemeine Suche | âœ… | Free Tier | â­â­â­ |
| **DuckDuckGo** | PrivatsphÃ¤re, kein Tracking | Inoffiziell | Kostenlos | â­â­â­ |

### Empfehlung
- **Tavily** als Haupttool (bereits in HayMAS)
- **Brave** als kostenloser Fallback

---

## Tier 2: News & AktualitÃ¤t

FÃ¼r aktuelle Ereignisse, Trends, Breaking News.

| Tool | Beschreibung | API | Kosten | QualitÃ¤t |
|------|--------------|-----|--------|----------|
| **Google News (gnews)** | Aggregiert News weltweit | Scraping | Kostenlos | â­â­â­â­ |
| **NewsAPI.org** | 80.000+ Quellen, strukturiert | âœ… | Free Tier (100/Tag) | â­â­â­â­â­ |
| **Mediastack** | Globale News, viele Sprachen | âœ… | Free Tier | â­â­â­â­ |
| **GDELT Project** | Weltnachrichten-DB, Sentiment | BigQuery | Kostenlos | â­â­â­â­ |
| **Event Registry** | Events aus News extrahiert | âœ… | Paid | â­â­â­â­â­ |
| **Newscatcher** | News-Aggregation API | âœ… | Paid | â­â­â­â­ |

### Code-Beispiel: gnews

```python
from gnews import GNews

def google_news_search(query: str, max_results: int = 10):
    gnews = GNews(language="de", country="DE", period="7d", max_results=max_results)
    results = gnews.get_news(query)
    return [{
        "title": r.get("title"),
        "url": r.get("url"),
        "published": r.get("published date"),
        "source": r.get("publisher", {}).get("title")
    } for r in results]
```

### Empfehlung
- **gnews** fÃ¼r kostenlose News-Suche (bereits im Newsletter-Projekt)
- **NewsAPI.org** fÃ¼r strukturierte, zuverlÃ¤ssige News

---

## Tier 3: Wissenschaft & Forschung

FÃ¼r wissenschaftliche Fragen, Studien, Paper.

| Tool | Beschreibung | API | Kosten | QualitÃ¤t |
|------|--------------|-----|--------|----------|
| **Semantic Scholar** | 200M+ Paper, AI-Zusammenfassungen | âœ… | Kostenlos | â­â­â­â­â­ |
| **arXiv** | Preprints (ML, Physik, Math, CS) | âœ… | Kostenlos | â­â­â­â­â­ |
| **PubMed/NCBI** | Medizinische Forschung | âœ… | Kostenlos | â­â­â­â­â­ |
| **OpenAlex** | 250M+ wissenschaftliche Werke | âœ… | Kostenlos | â­â­â­â­â­ |
| **Crossref** | DOI-Lookup, Paper-Metadaten | âœ… | Kostenlos | â­â­â­â­ |
| **CORE** | Open Access Paper | âœ… | Kostenlos | â­â­â­â­ |
| **Google Scholar** | Via SerpAPI | SerpAPI | Paid | â­â­â­â­â­ |

### Code-Beispiel: Semantic Scholar

```python
import httpx

async def semantic_scholar_search(query: str, limit: int = 10):
    url = "https://api.semanticscholar.org/graph/v1/paper/search"
    params = {
        "query": query,
        "limit": limit,
        "fields": "title,abstract,year,authors,citationCount,url"
    }
    async with httpx.AsyncClient() as client:
        response = await client.get(url, params=params)
        data = response.json()
        return data.get("data", [])
```

### Empfehlung
- **Semantic Scholar** als Haupttool fÃ¼r Wissenschaft
- **arXiv** speziell fÃ¼r Tech/ML/KI-Themen

---

## Tier 4: Unternehmen & Wirtschaft

FÃ¼r Firmendaten, Finanzen, Marktanalysen.

| Tool | Beschreibung | API | Kosten | QualitÃ¤t |
|------|--------------|-----|--------|----------|
| **OpenCorporates** | 200M+ Firmen weltweit | âœ… | Free Tier | â­â­â­â­ |
| **North Data** | Deutsche Firmen, Verflechtungen | âœ… | â‚¬â‚¬â‚¬ | â­â­â­â­â­ |
| **Handelsregister** | Offizielle DE-Firmendaten | Scraping | Kostenlos | â­â­â­â­ |
| **Crunchbase** | Startups, Funding, Investoren | âœ… | $$$ | â­â­â­â­â­ |
| **SEC EDGAR** | US-BÃ¶rsenberichte | âœ… | Kostenlos | â­â­â­â­â­ |
| **Bundesanzeiger** | JahresabschlÃ¼sse DE | Scraping | Kostenlos | â­â­â­â­ |
| **OpenSanctions** | Sanktionslisten, PEPs | âœ… | Kostenlos | â­â­â­â­ |

### Code-Beispiel: OpenCorporates

```python
import httpx

async def company_search(query: str, jurisdiction: str = "de"):
    url = "https://api.opencorporates.com/v0.4/companies/search"
    params = {"q": query, "jurisdiction_code": jurisdiction}
    async with httpx.AsyncClient() as client:
        response = await client.get(url, params=params)
        data = response.json()
        return data.get("results", {}).get("companies", [])
```

### Empfehlung
- **OpenCorporates** fÃ¼r internationale Firmensuche (kostenlos)
- **Bundesanzeiger** fÃ¼r deutsche JahresabschlÃ¼sse

---

## Tier 5: Patente & IP

FÃ¼r Patentrecherchen, Erfindungen, Intellectual Property.

| Tool | Beschreibung | API | Kosten | QualitÃ¤t |
|------|--------------|-----|--------|----------|
| **Espacenet (EPO)** | EuropÃ¤ische Patente | âœ… | Kostenlos | â­â­â­â­â­ |
| **DPMA** | Deutsche Patente & Marken | âœ… | Kostenlos | â­â­â­â­â­ |
| **USPTO** | US-Patente | âœ… | Kostenlos | â­â­â­â­â­ |
| **Lens.org** | Open Patent Database | âœ… | Kostenlos | â­â­â­â­â­ |
| **Google Patents** | Globale Suche | Via SerpAPI | Paid | â­â­â­â­ |
| **WIPO** | Internationale PCT-Patente | âœ… | Kostenlos | â­â­â­â­ |

### Code-Beispiel: Espacenet

```python
import httpx

async def patent_search(query: str, limit: int = 10):
    # Espacenet Open Patent Services (OPS)
    url = "https://ops.epo.org/3.2/rest-services/published-data/search/biblio"
    params = {"q": f"txt={query}", "Range": f"1-{limit}"}
    headers = {"Accept": "application/json"}
    # Hinweis: BenÃ¶tigt OAuth2-Token fÃ¼r Production
    async with httpx.AsyncClient() as client:
        response = await client.get(url, params=params, headers=headers)
        return response.json()
```

### Empfehlung
- **Lens.org** fÃ¼r einfachen Einstieg (keine Auth nÃ¶tig)
- **Espacenet OPS** fÃ¼r professionelle Nutzung

---

## Tier 6: Ã–ffentliche Verwaltung & Recht

FÃ¼r Gesetze, Urteile, Ausschreibungen.

| Tool | Beschreibung | API | Kosten | QualitÃ¤t |
|------|--------------|-----|--------|----------|
| **TED (EU)** | EU-Ausschreibungen | âœ… | Kostenlos | â­â­â­â­â­ |
| **Bund.de Vergabe** | DE-Ausschreibungen | Scraping | Kostenlos | â­â­â­â­ |
| **DTVP** | Deutsches Vergabeportal | âœ… | Kostenlos | â­â­â­â­ |
| **EUR-Lex** | EU-Gesetze und Urteile | âœ… | Kostenlos | â­â­â­â­â­ |
| **Gesetze-im-Internet** | Alle DE-Gesetze | Scraping | Kostenlos | â­â­â­â­â­ |
| **OpenLegalData** | DE-Gerichtsurteile | âœ… | Kostenlos | â­â­â­â­ |
| **dejure.org** | Rechtsprechung, Kommentare | Scraping | Kostenlos | â­â­â­â­ |

### Code-Beispiel: TED API

```python
import httpx

async def tender_search(query: str, country: str = "DE"):
    url = "https://ted.europa.eu/api/v3.0/notices/search"
    params = {
        "q": query,
        "fields": "title,buyer,publicationDate,estimatedValue",
        "country": country,
        "size": 20
    }
    async with httpx.AsyncClient() as client:
        response = await client.get(url, params=params)
        return response.json()
```

### Empfehlung
- **TED API** fÃ¼r Ã¶ffentliche Ausschreibungen
- **Gesetze-im-Internet** + **dejure.org** fÃ¼r Rechtsfragen

---

## Tier 7: Statistik & Open Data

FÃ¼r Zahlen, Fakten, offizielle Statistiken.

| Tool | Beschreibung | API | Kosten | QualitÃ¤t |
|------|--------------|-----|--------|----------|
| **Destatis (GENESIS)** | Offizielle DE-Statistiken | âœ… | Kostenlos | â­â­â­â­â­ |
| **Eurostat** | EU-Statistiken | âœ… | Kostenlos | â­â­â­â­â­ |
| **World Bank** | Globale Wirtschaftsdaten | âœ… | Kostenlos | â­â­â­â­â­ |
| **OECD Data** | LÃ¤ndervergleiche | âœ… | Kostenlos | â­â­â­â­â­ |
| **GovData.de** | Open Data Portal DE | âœ… | Kostenlos | â­â­â­â­ |
| **data.gov** | US Open Data | âœ… | Kostenlos | â­â­â­â­ |
| **Our World in Data** | Visualisierte Statistiken | Download | Kostenlos | â­â­â­â­â­ |

### Code-Beispiel: Destatis GENESIS

```python
import httpx

async def destatis_search(query: str):
    url = "https://www-genesis.destatis.de/genesisWS/rest/2020/find/find"
    params = {
        "username": "GUEST",
        "password": "GUEST",
        "term": query,
        "language": "de"
    }
    async with httpx.AsyncClient() as client:
        response = await client.get(url, params=params)
        return response.json()
```

### Empfehlung
- **Destatis** fÃ¼r deutsche Statistiken
- **Our World in Data** fÃ¼r globale Trends mit Kontext

---

## Tier 8: Social Media & Trends

FÃ¼r Meinungen, Diskussionen, Sentiment.

| Tool | Beschreibung | API | Kosten | QualitÃ¤t |
|------|--------------|-----|--------|----------|
| **Reddit API** | Diskussionen, Communities | âœ… | Kostenlos (Limits) | â­â­â­â­ |
| **Hacker News** | Tech-Community | âœ… | Kostenlos | â­â­â­â­â­ |
| **Google Trends** | Suchtrends Ã¼ber Zeit | Inoffiziell | Kostenlos | â­â­â­â­ |
| **YouTube Data** | Video-Metadaten | âœ… | Kostenlos | â­â­â­â­ |
| **Stack Overflow** | Technische Q&A | âœ… | Kostenlos | â­â­â­â­â­ |
| **Twitter/X** | Echtzeit-Trends | âœ… | $$$ (eingeschrÃ¤nkt) | â­â­â­ |

### Code-Beispiel: Hacker News

```python
import httpx

async def hackernews_search(query: str, limit: int = 10):
    url = "https://hn.algolia.com/api/v1/search"
    params = {"query": query, "hitsPerPage": limit}
    async with httpx.AsyncClient() as client:
        response = await client.get(url, params=params)
        data = response.json()
        return [{
            "title": hit.get("title"),
            "url": hit.get("url"),
            "points": hit.get("points"),
            "comments": hit.get("num_comments")
        } for hit in data.get("hits", [])]
```

### Empfehlung
- **Hacker News** fÃ¼r Tech-Themen (beste kostenlose API)
- **Reddit** fÃ¼r breite Meinungsbilder

---

## Tier 9: Wissens-Datenbanken

FÃ¼r strukturiertes Faktenwissen.

| Tool | Beschreibung | API | Kosten | QualitÃ¤t |
|------|--------------|-----|--------|----------|
| **Wikipedia** | EnzyklopÃ¤disches Wissen | âœ… | Kostenlos | â­â­â­â­â­ |
| **Wikidata** | Strukturiertes Weltwissen | SPARQL | Kostenlos | â­â­â­â­â­ |
| **DBpedia** | Wikipedia als Linked Data | SPARQL | Kostenlos | â­â­â­â­ |
| **Wolfram Alpha** | Berechnungen, Fakten | âœ… | $ | â­â­â­â­â­ |

### Code-Beispiel: Wikipedia

```python
import httpx

async def wikipedia_search(query: str, limit: int = 5):
    url = "https://de.wikipedia.org/w/api.php"
    params = {
        "action": "query",
        "list": "search",
        "srsearch": query,
        "srlimit": limit,
        "format": "json"
    }
    async with httpx.AsyncClient() as client:
        response = await client.get(url, params=params)
        data = response.json()
        return data.get("query", {}).get("search", [])

async def wikipedia_summary(title: str):
    url = "https://de.wikipedia.org/api/rest_v1/page/summary/" + title
    async with httpx.AsyncClient() as client:
        response = await client.get(url)
        return response.json()
```

### Empfehlung
- **Wikipedia** als Fakten-Grundlage fÃ¼r jeden Agenten

---

## Best Practices

### 1. Layered Search Strategy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 1: Orientierung                                       â”‚
â”‚  â†’ Tavily/Google fÃ¼r Ãœberblick                              â”‚
â”‚  â†’ Wikipedia fÃ¼r Grundlagen                                  â”‚
â”‚  â†’ Google Trends fÃ¼r AktualitÃ¤t                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 2: Tiefe                                              â”‚
â”‚  â†’ Spezialisierte DBs je nach Thema                         â”‚
â”‚  â†’ Semantic Scholar fÃ¼r Forschung                           â”‚
â”‚  â†’ News APIs fÃ¼r aktuelle Entwicklungen                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 3: Validierung                                        â”‚
â”‚  â†’ PrimÃ¤rquellen (Gesetze, Patente, Studien)               â”‚
â”‚  â†’ Offizielle Statistiken (Destatis, Eurostat)             â”‚
â”‚  â†’ Cross-Check mit mehreren Quellen                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Topic-Based Tool Routing

```python
TOOL_ROUTING = {
    "tech_aktuell": ["tavily", "hacker_news", "arxiv", "google_news"],
    "wissenschaft": ["semantic_scholar", "pubmed", "arxiv", "crossref"],
    "unternehmen": ["opencorporates", "northdata", "crunchbase", "news"],
    "recht_de": ["gesetze_im_internet", "dejure", "openlegaldata"],
    "patent": ["espacenet", "dpma", "google_patents", "lens"],
    "vergabe": ["ted_api", "bund_vergabe", "dtvp"],
    "statistik": ["destatis", "eurostat", "worldbank"],
    "meinung": ["reddit", "twitter", "hacker_news", "youtube"],
    "grundlagen": ["wikipedia", "wikidata", "tavily"],
}
```

### 3. Deep Research Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: Query Expansion                                     â”‚
â”‚  â€¢ Kernfrage â†’ 5-10 Sub-Fragen generieren                    â”‚
â”‚  â€¢ Synonyme und verwandte Begriffe                           â”‚
â”‚  â€¢ Verschiedene Sprachen (DE + EN)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PHASE 2: Broad Search                                        â”‚
â”‚  â€¢ Alle Sub-Fragen parallel suchen                           â”‚
â”‚  â€¢ Verschiedene Quellen-Typen abdecken                       â”‚
â”‚  â€¢ 50-100 Quellen sammeln                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PHASE 3: Deep Dive                                           â”‚
â”‚  â€¢ Top-Quellen im Volltext lesen                             â”‚
â”‚  â€¢ Referenzen verfolgen (Citation Chaining)                  â”‚
â”‚  â€¢ PrimÃ¤rquellen identifizieren                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PHASE 4: Synthesis                                           â”‚
â”‚  â€¢ WidersprÃ¼che identifizieren                               â”‚
â”‚  â€¢ Konsens vs. Kontroverse                                   â”‚
â”‚  â€¢ QuellenqualitÃ¤t bewerten                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Priorisierte Implementierungs-Roadmap fÃ¼r HayMAS

### Phase 1: Quick Wins (sofort)

| Tool | Aufwand | Impact |
|------|---------|--------|
| Google News (gnews) | 1h | â­â­â­â­â­ |
| Wikipedia API | 1h | â­â­â­â­â­ |
| Hacker News | 30min | â­â­â­â­ |

### Phase 2: Wissenschaft & Fakten

| Tool | Aufwand | Impact |
|------|---------|--------|
| Semantic Scholar | 2h | â­â­â­â­â­ |
| arXiv | 1h | â­â­â­â­ |

### Phase 3: Business & Recht

| Tool | Aufwand | Impact |
|------|---------|--------|
| OpenCorporates | 2h | â­â­â­â­ |
| TED API | 2h | â­â­â­â­ |

### Phase 4: Statistik & Deep Research

| Tool | Aufwand | Impact |
|------|---------|--------|
| Destatis | 3h | â­â­â­â­ |
| Tool-Routing im Orchestrator | 4h | â­â­â­â­â­ |

---

## Ressourcen & Links

### API-Dokumentationen
- Tavily: https://docs.tavily.com/
- Semantic Scholar: https://api.semanticscholar.org/
- NewsAPI: https://newsapi.org/docs
- OpenCorporates: https://api.opencorporates.com/documentation
- TED: https://ted.europa.eu/TED/misc/helpPage.do?helpPageId=api
- Destatis: https://www-genesis.destatis.de/genesis/online

### Python-Libraries
- `gnews` - Google News Scraping
- `feedparser` - RSS-Feeds
- `scholarly` - Google Scholar (inoffiziell)
- `wikipedia-api` - Wikipedia
- `arxiv` - arXiv API Client

---

*Erstellt: Januar 2026*
*FÃ¼r: HayMAS Multi-Agent Research System*
